---
title: "Hands-on Exercise 9: Geographically Weighted Predictive Models"
author: "Emily Aurelia"
format:
  html:
    toc-depth: 4
execute: 
  warning: false #to remove the warning in the webpage
  freeze: True
date: "16 March 2024"
---

# Overview

When dealing with predictions, we want to predict what is the outcome in the future. To do this, we need to identify the set of predictors/variables that affects the predicted variables. Geospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. This means that the occurrences of event are neither uniform nor random in distribution over space when geographically referenced data are used. Geospatial predictive modeling attempts to describe the factors that constrain and influence where the locations of events occur by sptially correlating occurrences of historical geosptail locations with environmental factors that represent those constraints and influences.

# Data

## Aspatial Data

-   HDB Resale Data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from Data.gov.sg.

## Geospatial Data

-    MP14_SUBZONE_WEB_PL: a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg

## Locational factors

-   **Locational factors with geographic coordinates**:

    -   Downloaded from **Data.gov.sg**.

        -   **Eldercare** data is a list of eldercare in Singapore. It is in shapefile format.

        -   **Hawker Centre** data is a list of hawker centres in Singapore. It is in geojson format.

        -   **Parks** data is a list of parks in Singapore. It is in geojson format.

        -   **Supermarket** data is a list of supermarkets in Singapore. It is in geojson format.

        -   **CHAS clinics** data is a list of CHAS clinics in Singapore. It is in geojson format.

        -   **Childcare service** data is a list of childcare services in Singapore. It is in geojson format.

        -   **Kindergartens** data is a list of kindergartens in Singapore. It is in geojson format.

    -   Downloaded from **Datamall.lta.gov.sg**.

        -   **MRT** data is a list of MRT/LRT stations in Singapore with the station names and codes. It is in shapefile format.

        -   **Bus stops** data is a list of bus stops in Singapore. It is in shapefile format.

-   **Locational factors without geographic coordinates**:

    -   Downloaded from **Data.gov.sg**.

        -   **Primary school** data is extracted from the list on General information of schools from data.gov portal. It is in csv format.

    -   Retrieved/Scraped from **other sources**

        -   **CBD** coordinates obtained from Google.

        -   **Shopping malls** data is a list of Shopping malls in Singapore obtained from [Wikipedia](https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Singapore).

        -   **Good primary schools** is a list of primary schools that are ordered in ranking in terms of popularity and this can be found at [Local Salary Forum](https://www.salary.sg/2021/best-primary-schools-2021-by-popularity).

# Installing and Loading R packages

```{r}
pacman::p_load(sf, spdep, GWmodel, SpatialML, 
               tmap, rsample, Metrics, tidyverse)
```

# Preparing Data

### Reading data file to rds

```{r}
mdata <- read_rds("data/aspatial/mdata.rds")
```

### Data Sampling

We split the training and test satasets into 65:35 ratio using initial_split() function of rsample package.

```{r}
set.seed(1234)
resale_split <- initial_split(mdata, 
                              prop = 6.5/10,)
train_data <- training(resale_split)
test_data <- testing(resale_split)
```

```{r}
#| eval: false
write_rds(train_data, "data/aspatial/train_data.rds")
write_rds(test_data, "data/aspatial/test_data.rds")
```

# Computing Correlation Matrix

Let us examine the correlation matrix to see if there is a sign of multicolinearity.

```{r}
mdata_nogeo <- mdata %>%
  st_drop_geometry()
corrplot::corrplot(cor(mdata_nogeo[, 2:17]), 
                   diag = FALSE, 
                   order = "AOE",
                   tl.pos = "td", 
                   tl.cex = 0.5, 
                   method = "number", 
                   type = "upper")
```

Looking at the values in the correlation matrix, all the values are below 0.8 which means there are no sign of multicolinearity.

# Retrieving the Stored Data

```{r}
train_data <- read_rds("data/aspatial/train_data.rds")
test_data <- read_rds("data/aspatial/test_data.rds")
```

# Building a non-spatial multiple linear regression

From the previous hands-on exercise, we can do this by using the lm() function for the multiple linear regression method.

```{r}
#| eval: false
price_mlr <- lm(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                data=train_data)
summary(price_mlr)
```

```{r}
#| eval: false
write_rds(price_mlr, "data/aspatial/price_mlr.rds" ) 
```

# GWR Predictive Method

We will be using geographically weighted method of GWmodel package to predict HDB resale prices.

## Converting the sf data.frame to SpatialPointDataFrame

```{r}
train_data_sp <- as_Spatial(train_data)
train_data_sp
```

## Computing adaptive bandwidth

We then use bw.gwr() of GWmodel package to find the optimal bandwidth to be used.

```{r}
#| eval: false
bw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                  data=train_data_sp,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)
```

The result shows that 40 neighbour points will be the optimal bandwidth to be used if adaptive bandwidth is used for this data set.

```{r}
#| eval: false
write_rds(bw_adaptive, "data/aspatial/bw_adaptive.rds")
```

## Constructing the adaptive bandwidth GWR model

Let's first call the saved bandwidth

```{r}
bw_adaptive <- read_rds("data/aspatial/bw_adaptive.rds")
```

Then, we calibrate the gwr-based hedonic pricing model using the adaptive bandwidth adn Gaussian kernel.

```{r}
#|eval: false
gwr_adaptive <- gwr.basic(formula = resale_price ~
                            floor_area_sqm + storey_order +
                            remaining_lease_mths + PROX_CBD + 
                            PROX_ELDERLYCARE + PROX_HAWKER +
                            PROX_MRT + PROX_PARK + PROX_MALL + 
                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                            WITHIN_1KM_PRISCH,
                          data=train_data_sp,
                          bw=bw_adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE,
                          longlat = FALSE)
```

```{r}
#| eval: false
write_rds(gwr_adaptive, "data/aspatial/gwr_adaptive.rds")
```

## Retrieve GWR output object

```{r}
gwr_adaptive <- read_rds("data/aspatial/gwr_adaptive.rds")
```

To show the output:

```{r}
gwr_adaptive
```
## Converting the test data from sf data.frame to SpatialPointDataFrame

```{r}
test_data_sp <- test_data %>%
  as_Spatial()
test_data_sp
```
## Computing adaptive bandwidth for the test data

```{r}
gwr_bw_test_adaptive <- bw.gwr(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                  data=test_data_sp,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)
```
From the result above, we can see that the optimal bandwidth to be used for the test data is 25 neighbour.

## Computing predicted values of the test data

```{r}
#| eval: false
gwr_pred <- gwr.predict(formula = resale_price ~
                            floor_area_sqm + storey_order +
                            remaining_lease_mths + PROX_CBD + 
                            PROX_ELDERLYCARE + PROX_HAWKER +
                            PROX_MRT + PROX_PARK + PROX_MALL + 
                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                            WITHIN_1KM_PRISCH, 
                        data=train_data_sp, 
                        predictdata = test_data_sp, 
                        bw=gwr_bw_test_adaptive,
                        kernel = 'gaussian', 
                        adaptive=TRUE, 
                        longlat = FALSE)
```

# Preparing coordinates data

## Extracting coordinates data

We can use st_coordiantes() from the sf package to extract the x and y coordiantes of the full, training and test datasets.

```{r}
coords <- st_coordinates(mdata)
coords_train <- st_coordinates(train_data)
coords_test <- st_coordinates(test_data)
```

```{r}
coords_train <- write_rds(coords_train, "data/aspatial/coords_train.rds" )
coords_test <- write_rds(coords_test, "data/aspatial/coords_test.rds" )
```

## Dropping the geometry column

We can use st_drop_geometry() from the sf package to drop the geometry column.

```{r}
train_data <- train_data %>% 
  st_drop_geometry()
```


# Calibrating Random Forest Model

Now let's caliberate a model to predict HDB prive by using random forest function of ranger package.

```{r}
set.seed(1234)
rf <- ranger(resale_price ~ floor_area_sqm + storey_order + 
               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + 
               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + 
               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
               WITHIN_1KM_PRISCH,
             data=train_data)
rf
```
```{r}
#| eval: false
write_rds(rf, "data/aspatial/rf.rds")
```

```{r}
rf <- read_rds("data/aspatial/rf.rds")
rf
```
# Calibrating Geographical Random Forest model

We can use the grf() function of the SpatialML package to calibrate the geographical random forest model

## Calibrating using training data

```{r}
#| eval: false
set.seed(1234)
gwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + storey_order +
                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +
                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +
                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                       WITHIN_1KM_PRISCH,
                     dframe=train_data, 
                     bw=55,
                     kernel="adaptive",
                     coords=coords_train)
```
```{r}
#| eval: false
write_rds(gwRF_adaptive, "data/aspatial/gwRF_adaptive.rds")
```

```{r}
gwRF_adaptive <- read_rds("data/aspatial/gwRF_adaptive.rds")
```

## Predicting by using test data

### Preparing the test data

```{r}
test_data <- cbind(test_data, coords_test) %>%
  st_drop_geometry()
```

### PRedicting with test data

We use predict.grf() function of the SpatialML package to predict the HDB resale value by using the test data and the calibrated geographical random forest model.

```{r}
#| eval: false
gwRF_pred <- predict.grf(gwRF_adaptive, 
                           test_data, 
                           x.var.name="X",
                           y.var.name="Y", 
                           local.w=1,
                           global.w=0)
```

```{r}
#| eval: false
GRF_pred <- write_rds(gwRF_pred, "data/aspatial/GRF_pred.rds")
```

### Converting the predicting output into a data frame

The output of the predict.grf() is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.

```{r}
GRF_pred <- read_rds("data/aspatial/GRF_pred.rds")
GRF_pred_df <- as.data.frame(GRF_pred)
```

In the code chunk below, cbind() is used to append the predicted values onto test_data

```{r}
test_data_p <- cbind(test_data, GRF_pred_df)
```

```{r}
#| eval: false
write_rds(test_data_p, "data/aspatial/test_data_p.rds")
```

## Calculating Root Mean Square Error

The root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.

```{r}
rmse(test_data_p$resale_price, 
     test_data_p$GRF_pred)
```

## Visualizing the predicted values

Alternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.

```{r}
test_data_p <- test_data_p |> select(1:19)
ggplot(data = test_data_p,
       aes(x = GRF_pred,
           y = resale_price)) +
  geom_point()
```

A better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model.


